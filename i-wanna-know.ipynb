{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55m8dTg3OdK"
      },
      "source": [
        "# Project: I Wanna Know\n",
        "\n",
        "This project is an application designed for inspiration, in-depth reading, and exploration of popular topics. The idea is to start with 100 categories, each containing 100 finely curated topics. For example, if you choose the psychology category, you'll encounter topics like Gestalt psychology, where a concise, 5-page summary covers the essentials—with potential follow-up prompts added later.\n",
        "\n",
        "## Implementation:\n",
        "A specialized model processes millions of text lines from the internet to form clusters through topic modeling. Each cluster is then analyzed to extract and develop detailed topics. This approach is inspired by the deep research methodology seen in platforms like Perplexity (have you tried it?), offering a unique, customizable format for engaging with content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe_5RSnf3OdM"
      },
      "source": [
        "## Running the project:\n",
        "\n",
        "You will need conda (aka miniconda) as your python env manager.\n",
        "1. Install [miniconda](https://docs.conda.io/projects/conda/en/stable/index.html)\n",
        "2. Init your env:\n",
        "    - `conda create -n bertopic_env python=3.9`\n",
        "    - `conda activate bertopic_env`\n",
        "    - `conda install jupyter`\n",
        "3. Run jupyter\n",
        "    - `jupyter notebook`\n",
        "\n",
        "known issues:\n",
        "1. Conda init:\n",
        "    - [https://community.anaconda.cloud/](https://community.anaconda.cloud/t/unable-to-activate-environment-prompted-to-run-conda-init-before-conda-activate-but-it-doesnt-work/68677)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "id": "dXRx0dxc3OdM",
        "outputId": "42508b51-ae57-4a46-dee8-20a801d74b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bertopic\n",
            "  Downloading bertopic-0.16.4-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting hdbscan>=0.8.29 (from bertopic)\n",
            "  Using cached hdbscan-0.8.40-cp39-cp39-macosx_10_9_universal2.whl\n",
            "Collecting numpy>=1.20.0 (from bertopic)\n",
            "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
            "Collecting pandas>=1.1.5 (from bertopic)\n",
            "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (89 kB)\n",
            "Collecting plotly>=4.7.0 (from bertopic)\n",
            "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting scikit-learn>=0.22.2.post1 (from bertopic)\n",
            "  Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (31 kB)\n",
            "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tqdm>=4.41.1 (from bertopic)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting umap-learn>=0.5.0 (from bertopic)\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting scipy>=1.0 (from hdbscan>=0.8.29->bertopic)\n",
            "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.0 (from hdbscan>=0.8.29->bertopic)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas>=1.1.5->bertopic)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.1.5->bertopic)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting narwhals>=1.15.1 (from plotly>=4.7.0->bertopic)\n",
            "  Downloading narwhals-1.27.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (24.2)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.22.2.post1->bertopic)\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading torch-2.6.0-cp39-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
            "Collecting huggingface-hub>=0.20.0 (from sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting Pillow (from sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading pillow-11.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
            "Collecting numba>=0.51.2 (from umap-learn>=0.5.0->bertopic)\n",
            "  Downloading numba-0.60.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.2->umap-learn>=0.5.0->bertopic)\n",
            "  Downloading llvmlite-0.43.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Collecting networkx (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.5)\n",
            "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/bertopic_env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.1.31)\n",
            "Downloading bertopic-0.16.4-py3-none-any.whl (143 kB)\n",
            "Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
            "Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
            "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading narwhals-1.27.1-py3-none-any.whl (308 kB)\n",
            "Downloading numba-0.60.0-cp39-cp39-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading torch-2.6.0-cp39-none-macosx_11_0_arm64.whl (66.5 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hUsing cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Downloading pillow-11.1.0-cp39-cp39-macosx_11_0_arm64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "Downloading llvmlite-0.43.0-cp39-cp39-macosx_11_0_arm64.whl (28.8 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
            "Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl (408 kB)\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: pytz, mpmath, tzdata, tqdm, threadpoolctl, sympy, safetensors, regex, Pillow, numpy, networkx, narwhals, llvmlite, joblib, fsspec, filelock, torch, scipy, plotly, pandas, numba, huggingface-hub, tokenizers, scikit-learn, transformers, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
            "Successfully installed Pillow-11.1.0 bertopic-0.16.4 filelock-3.17.0 fsspec-2025.2.0 hdbscan-0.8.40 huggingface-hub-0.29.1 joblib-1.4.2 llvmlite-0.43.0 mpmath-1.3.0 narwhals-1.27.1 networkx-3.2.1 numba-0.60.0 numpy-2.0.2 pandas-2.2.3 plotly-6.0.0 pynndescent-0.5.13 pytz-2025.1 regex-2024.11.6 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.13.1 sentence-transformers-3.4.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0 tzdata-2025.1 umap-learn-0.5.7\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "pIbR4G9R3OdM"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNF9_CAM3OdN"
      },
      "outputs": [],
      "source": [
        "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "439137190270424eaa0891c8a25036a3",
            "48966a597a294325b471d33d7f7f887f",
            "0c11e42a5d434e87925694b88506f3cf",
            "68fef7df929046359d4e8ff7dc5201cd",
            "06cbdd5ac24843a7b19f1c4298d96284",
            "d1a147efbf08499da89985856bcbcf30",
            "25ced175f381459ca37c8e95dbb2ff22",
            "3f90cbd133b14f16a0b2c490d7054f2c",
            "b92c340376b94743823992d130f0785b",
            "e5882b860c8c4c82a2fc7824f5005e31",
            "6144e011208d4b90aaeb2b7e84645b5e"
          ]
        },
        "id": "LiqE2Wdn3OdN",
        "outputId": "53ee8033-97d1-416c-96af-95a59e3fa32e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "439137190270424eaa0891c8a25036a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48966a597a294325b471d33d7f7f887f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c11e42a5d434e87925694b88506f3cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68fef7df929046359d4e8ff7dc5201cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06cbdd5ac24843a7b19f1c4298d96284",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1a147efbf08499da89985856bcbcf30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25ced175f381459ca37c8e95dbb2ff22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f90cbd133b14f16a0b2c490d7054f2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b92c340376b94743823992d130f0785b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5882b860c8c4c82a2fc7824f5005e31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6144e011208d4b90aaeb2b7e84645b5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "topic_model = BERTopic()\n",
        "topics, probs = topic_model.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2PjoUc03OdN",
        "outputId": "59601406-5d3d-461a-855e-8072054b7382"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>6640</td>\n",
              "      <td>-1_to_the_is_and</td>\n",
              "      <td>[to, the, is, and, of, for, you, in, it, that]</td>\n",
              "      <td>[It's like refusing 'God's kingdom come'.\\n\\nI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1828</td>\n",
              "      <td>0_game_team_games_he</td>\n",
              "      <td>[game, team, games, he, players, season, hocke...</td>\n",
              "      <td>[\\n\\n\"Deeply rooted rivalry?\" Ahem, Jokerit ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>580</td>\n",
              "      <td>1_key_clipper_chip_encryption</td>\n",
              "      <td>[key, clipper, chip, encryption, keys, escrow,...</td>\n",
              "      <td>[The following document summarizes the Clipper...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>526</td>\n",
              "      <td>2_ites_cheek_yep_huh</td>\n",
              "      <td>[ites, cheek, yep, huh, ken, forget, why, lets...</td>\n",
              "      <td>[\\nHuh?, \\nYep.\\n, ites:]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>482</td>\n",
              "      <td>3_israel_israeli_jews_arab</td>\n",
              "      <td>[israel, israeli, jews, arab, jewish, arabs, p...</td>\n",
              "      <td>[From: Center for Policy Research &lt;cpr&gt;\\nSubje...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>209</td>\n",
              "      <td>10</td>\n",
              "      <td>209_table_tables_sale_2end</td>\n",
              "      <td>[table, tables, sale, 2end, 1coffee, foldable,...</td>\n",
              "      <td>[Moving Sale: Must sell before May 5:\\nFuton: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>210</td>\n",
              "      <td>10</td>\n",
              "      <td>210_dod_denizens_doom_motorcycle</td>\n",
              "      <td>[dod, denizens, doom, motorcycle, muck, recmot...</td>\n",
              "      <td>[This is probably a stupid question but as I a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>211</td>\n",
              "      <td>10</td>\n",
              "      <td>211_w4wg_network_lan_windows</td>\n",
              "      <td>[w4wg, network, lan, windows, wfw, workgroups,...</td>\n",
              "      <td>[This may be a simple question but:\\n\\nWe have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>212</td>\n",
              "      <td>10</td>\n",
              "      <td>212_media_publications_spiking_digging</td>\n",
              "      <td>[media, publications, spiking, digging, contri...</td>\n",
              "      <td>[\\n\\n\\nIs this the same Monolithic, Centrally ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>213</td>\n",
              "      <td>10</td>\n",
              "      <td>213_board_motherboard_wires_turbo</td>\n",
              "      <td>[board, motherboard, wires, turbo, switch, pin...</td>\n",
              "      <td>[I bought a 386DX-40 motherboard for 50$... no...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>215 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topic  Count                                    Name  \\\n",
              "0       -1   6640                        -1_to_the_is_and   \n",
              "1        0   1828                    0_game_team_games_he   \n",
              "2        1    580           1_key_clipper_chip_encryption   \n",
              "3        2    526                    2_ites_cheek_yep_huh   \n",
              "4        3    482              3_israel_israeli_jews_arab   \n",
              "..     ...    ...                                     ...   \n",
              "210    209     10              209_table_tables_sale_2end   \n",
              "211    210     10        210_dod_denizens_doom_motorcycle   \n",
              "212    211     10            211_w4wg_network_lan_windows   \n",
              "213    212     10  212_media_publications_spiking_digging   \n",
              "214    213     10       213_board_motherboard_wires_turbo   \n",
              "\n",
              "                                        Representation  \\\n",
              "0       [to, the, is, and, of, for, you, in, it, that]   \n",
              "1    [game, team, games, he, players, season, hocke...   \n",
              "2    [key, clipper, chip, encryption, keys, escrow,...   \n",
              "3    [ites, cheek, yep, huh, ken, forget, why, lets...   \n",
              "4    [israel, israeli, jews, arab, jewish, arabs, p...   \n",
              "..                                                 ...   \n",
              "210  [table, tables, sale, 2end, 1coffee, foldable,...   \n",
              "211  [dod, denizens, doom, motorcycle, muck, recmot...   \n",
              "212  [w4wg, network, lan, windows, wfw, workgroups,...   \n",
              "213  [media, publications, spiking, digging, contri...   \n",
              "214  [board, motherboard, wires, turbo, switch, pin...   \n",
              "\n",
              "                                   Representative_Docs  \n",
              "0    [It's like refusing 'God's kingdom come'.\\n\\nI...  \n",
              "1    [\\n\\n\"Deeply rooted rivalry?\" Ahem, Jokerit ha...  \n",
              "2    [The following document summarizes the Clipper...  \n",
              "3                            [\\nHuh?, \\nYep.\\n, ites:]  \n",
              "4    [From: Center for Policy Research <cpr>\\nSubje...  \n",
              "..                                                 ...  \n",
              "210  [Moving Sale: Must sell before May 5:\\nFuton: ...  \n",
              "211  [This is probably a stupid question but as I a...  \n",
              "212  [This may be a simple question but:\\n\\nWe have...  \n",
              "213  [\\n\\n\\nIs this the same Monolithic, Centrally ...  \n",
              "214  [I bought a 386DX-40 motherboard for 50$... no...  \n",
              "\n",
              "[215 rows x 5 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topic_model.get_topic_info()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}